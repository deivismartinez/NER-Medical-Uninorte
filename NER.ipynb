{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deivismartinez/NER-Medical-Uninorte/blob/main/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_md"
      ],
      "metadata": {
        "id": "7jNIcyoFAZlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "import json\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import spacy\n",
        "from matplotlib import pyplot as plt\n",
        "from math import ceil\n",
        "import shutil"
      ],
      "metadata": {
        "id": "Bo6h_ZufAWcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/record/4279323/files/meddocan.zip?download=1 -O meddocan.zip"
      ],
      "metadata": {
        "id": "2q1unnwOU8_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip meddocan.zip"
      ],
      "metadata": {
        "id": "k3MKJGmLU_Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"es_core_news_md\")"
      ],
      "metadata": {
        "id": "uZcj5ytyAR99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {}\n",
        "for path in (Path('dev'), Path('test'), Path('train')):\n",
        "    dir_path = Path('meddocan')/path/Path('brat')\n",
        "    filenames = tuple(f[:-4] for f in listdir(dir_path) if isfile(join(dir_path, f)) if f[-4:] == '.txt')\n",
        "    dataset[str(path)] = []\n",
        "    for file_name in filenames:\n",
        "      d = dict()\n",
        "      with open(dir_path/Path(file_name+'.txt'), 'r') as f:\n",
        "        dataset[str(path)].append({\"text\":f.read(),\"file\":file_name,\"file_name_path\":dir_path/Path(file_name+'.txt')})"
      ],
      "metadata": {
        "id": "pdwA4hf_VgEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/deivismartinez/NER-Medical-Uninorte/main/tag.json"
      ],
      "metadata": {
        "id": "xkXzSk_sSfdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_model(model_index):\n",
        "  models = [\n",
        "    {\"name\":\"roberta-large-bne-capitel-ner\", \"folder\":\"PlanTL-GOB-ES/\"},\n",
        "    {\"name\":\"roberta-base-bne-capitel-ner-plus\", \"folder\":\"PlanTL-GOB-ES/\"},\n",
        "    ]\n",
        "  if model_index > len(models):\n",
        "    print(\"Model index not exist, from 1 to \"+str(len(models)))\n",
        "    return None\n",
        "  else:\n",
        "    model = models[model_index-1].get(\"folder\") + models[model_index-1].get(\"name\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "1_xSXFOA63N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ner_pipe(model):\n",
        "  ner_pipe = pipeline(task=\"ner\", model = model)\n",
        "  return ner_pipe"
      ],
      "metadata": {
        "id": "wbJMT51z3MO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7E8mFQrrMB9"
      },
      "outputs": [],
      "source": [
        "file = open(\"tag.json\",\"r\")\n",
        "tag = json.load(file)\n",
        "file.close()\n",
        "def get_tag(entity):\n",
        "  tags=[\"LOC\",\"PER\",\"ORG\", \"OTH\"]\n",
        "  for tag_l in tags:\n",
        "    if tag_l in entity:\n",
        "      return tag[tag_l]\n",
        "  return \"NEW TAG\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer(model):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model,add_prefix_space=True)\n",
        "  do_grafic(tokenizer)\n",
        "  return tokenizer"
      ],
      "metadata": {
        "id": "6KdxtBtwYYUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_grafic(tokenizer):\n",
        "  token_length = [len(tokenizer(x.get('text'))['input_ids']) for x in dataset['train']]\n",
        "  plt.hist(token_length)"
      ],
      "metadata": {
        "id": "1hP-u5dtc7dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_start_end(list_values, n_string):\n",
        "  for entity in list_values:\n",
        "    entity[\"start\"] = entity.get(\"start\") + n_string\n",
        "    entity[\"end\"] = entity.get(\"end\") + n_string\n",
        "  return list_values"
      ],
      "metadata": {
        "id": "KqDha5mEcY-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_file(entity_list, file_name, min_score = 0.5):\n",
        "  t = 0\n",
        "  file= open(file_name,\"w\")\n",
        "  end_last = -1\n",
        "  word_last = \"\"\n",
        "  for entity in entity_list:\n",
        "      print('--------------Entity Actual::: ',entity['entity'],'-----------',entity['word'].replace('Ġ',' ').replace('Ã±','ñ').replace('Ã¡','á').replace('Ã©','é').replace('ÃŃ','í').replace('Ã³','ó').replace('Ãº','ú'))\n",
        "      if entity['score'] > min_score:\n",
        "        if entity['start'] == end_last or end_last == -1:\n",
        "          word_last += entity['word']\n",
        "          if end_last == -1:\n",
        "            start_first = entity['start']\n",
        "            entity_first = entity['entity']\n",
        "        else:\n",
        "          t += 1\n",
        "          end_now = entity['end']\n",
        "          entity_now = get_tag(entity_first)\n",
        "          row = 'T'+str(t) +'\\t'+ str(entity_now) +' ' + str(start_first) +' '+ str(end_last) +'\\t' + word_last +'\\n'\n",
        "          file.write(row)\n",
        "          word_last = entity['word']\n",
        "          start_first = entity['start']\n",
        "          entity_first = entity['entity']\n",
        "        end_last = entity['end']\n",
        "  t += 1\n",
        "  entity_now = get_tag(entity_first)\n",
        "  row = 'T'+str(t) +'\\t'+ str(entity_now) +' ' + str(start_first) +' '+ str(end_last) +'\\t' + word_last +'\\n'\n",
        "  file.write(row)\n",
        "  file.close ()"
      ],
      "metadata": {
        "id": "_kQbasPB_m05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_file_new(entity_list, file_name, min_score = 0.5):\n",
        "  t = 0\n",
        "  file= open(file_name,\"w\")\n",
        "  end_last = -1\n",
        "  entity_last = \"\"\n",
        "  word_last = \"\"\n",
        "  for entity in entity_list:\n",
        "      #print('--------------Entity Actual::: ',entity['entity'],'-----------',entity['word'].replace('Ġ',' ').replace('Ã±','ñ').replace('Ã¡','á').replace('Ã©','é').replace('ÃŃ','í').replace('Ã³','ó').replace('Ãº','ú'))\n",
        "      if entity['score'] > min_score:\n",
        "        if (entity['start'] == end_last or end_last == -1) or ((entity['start'] == (end_last+1)) \n",
        "        and get_tag(entity['entity']) == get_tag(entity_last)):\n",
        "          word_last += entity['word']\n",
        "          if end_last == -1:\n",
        "            start_first = entity['start']\n",
        "            entity_first = entity['entity']\n",
        "        else:\n",
        "          t += 1\n",
        "          end_now = entity['end']\n",
        "          entity_now = get_tag(entity_first)\n",
        "          row = 'T'+str(t) +'\\t'+ str(entity_now) +' ' + str(start_first) +' '+ str(end_last) +'\\t' + word_last.replace('Ġ',' ').replace('Ã±','ñ').replace('Ã¡','á').replace('Ã©','é').replace('ÃŃ','í').replace('Ã³','ó').replace('Ãº','ú') +'\\n'\n",
        "          if(entity_now!='OTHER'):\n",
        "            file.write(row)\n",
        "          word_last = entity['word']\n",
        "          start_first = entity['start']\n",
        "          entity_first = entity['entity']\n",
        "        end_last = entity['end']\n",
        "        entity_last = entity['entity']\n",
        "  t += 1\n",
        "  entity_now = get_tag(entity_first)\n",
        "  row = 'T'+str(t) +'\\t'+ str(entity_now) +' ' + str(start_first) +' '+ str(end_last) +'\\t' + word_last.replace('Ġ',' ').replace('Ã±','ñ').replace('Ã¡','á').replace('Ã©','é').replace('ÃŃ','í').replace('Ã³','ó').replace('Ãº','ú') +'\\n'\n",
        "  if(entity_now!='OTHER'):\n",
        "    file.write(row)\n",
        "  file.close ()"
      ],
      "metadata": {
        "id": "c18S3DUsSIlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_values_512(texto, ner_pipe, model_index=1):\n",
        "  max_length = 512\n",
        "  n_string = -1\n",
        "  ner_output = []\n",
        "  model = select_model(model_index)\n",
        "  if model != None:\n",
        "    tokenizer = get_tokenizer(model)\n",
        "    tokens = tokenizer(texto)['input_ids']\n",
        "    if len(tokens) > max_length:\n",
        "      n_partitions = ceil(len(tokens) / max_length)\n",
        "      for i in range(n_partitions):\n",
        "        end_index = (i+1)*max_length\n",
        "        if end_index > len(tokens):\n",
        "          end_index  = len(tokens) - 1 \n",
        "        token_sequence = tokens[i*max_length:end_index]\n",
        "        string_sequence = tokenizer.decode(token_sequence, \n",
        "                                          skip_special_tokens=True,\n",
        "                                          clean_up_tokenization_spaces=False)\n",
        "        new_list = change_start_end(ner_pipe(string_sequence), n_string)\n",
        "        ner_output.extend(new_list)\n",
        "        n_string = n_string + len(string_sequence)\n",
        "      if n_string != len(texto):\n",
        "        print(f'Original length: {len(texto)} vs Decoded Size {n_string}')\n",
        "    else:\n",
        "      ner_output.extend(ner_pipe(texto))\n",
        "  return ner_output"
      ],
      "metadata": {
        "id": "Kec7jy_SdRlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_values_sents(nlp_var, ner_pipe):\n",
        "  entity_list =  []\n",
        "  sum = 0\n",
        "  print(type(nlp_var))\n",
        "  for text_npl in nlp_var.sents:\n",
        "    for entity in ner_pipe(str(text_npl)):\n",
        "      entity[\"start\"] = entity.get(\"start\") + sum\n",
        "      entity[\"end\"] = entity.get(\"end\") + sum\n",
        "      entity_list.append(entity)\n",
        "    sum = sum + len(str(text_npl))\n",
        "  return entity_list"
      ],
      "metadata": {
        "id": "-oQ4eSm01KDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_values_split(text, ner_pipe):\n",
        "  entity_list =  []\n",
        "  text_split = text.split('.')\n",
        "  sum = 0\n",
        "  for text_npl in text_split:\n",
        "    print(text_npl)\n",
        "    for entity in ner_pipe(str(text_npl)):\n",
        "      entity[\"start\"] = entity.get(\"start\") + sum\n",
        "      entity[\"end\"] = entity.get(\"end\") + sum\n",
        "      entity_list.append(entity)\n",
        "    sum = sum + len(str(text_npl))\n",
        "  return entity_list"
      ],
      "metadata": {
        "id": "sY5XYlXSjXeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_file(text, file_name, folder_system, min_score,\n",
        "                 type_text, ner_pipe, model_index):\n",
        "  file_ann_name = folder_system + file_name + \".ann\"\n",
        "  nlp_var = nlp(text)\n",
        "  entity_list = []\n",
        "  if type_text == 0:\n",
        "    entity_list = ner_pipe(str(nlp_var))\n",
        "  elif type_text == 1:\n",
        "    entity_list = get_values_sents(nlp_var, ner_pipe = ner_pipe)\n",
        "  elif type_text == 2:\n",
        "    entity_list = get_values_512(text, ner_pipe = ner_pipe,\n",
        "                                 model_index=model_index)\n",
        "  elif type_text == 3:\n",
        "    entity_list = get_values_split(text, ner_pipe = ner_pipe)\n",
        "  else:\n",
        "    print(\"Type not exist\")\n",
        "  if len(entity_list) > 0:\n",
        "    build_file_new(entity_list,file_ann_name, min_score = min_score)"
      ],
      "metadata": {
        "id": "MUk9bJDioFaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def builder(min_score, quantity = 1, type_text = 0, model_index = 1):\n",
        "  model = select_model(model_index)\n",
        "  if model != None:\n",
        "    ner_pipe = get_ner_pipe(model)\n",
        "    folder_system = \"system/model_\"+str(model_index)+\"/test\"+str(type_text)+\"/\"\n",
        "    folder_gold = \"system/gold/\"\n",
        "    if not Path(folder_system).exists():\n",
        "      path = Path(folder_system)\n",
        "      path.mkdir(parents=True)\n",
        "    if not Path(folder_gold).exists():\n",
        "      path = Path(folder_gold)\n",
        "      path.mkdir(parents=True)\n",
        "    for text in dataset['test']:\n",
        "      #if text.get('file') == 'S0211-69952014000600016-1':\n",
        "      path_completo = str(text.get('file_name_path'))\n",
        "      path_completo = path_completo[:-4]\n",
        "      prepare_file(text.get('text'), text.get('file'), folder_system,\n",
        "                  min_score = min_score, type_text = type_text,\n",
        "                  ner_pipe = ner_pipe, model_index = model_index)\n",
        "      shutil.copy(path_completo+\".txt\", folder_gold+text.get('file')+\".txt\")\n",
        "      shutil.copy(path_completo+\".ann\", folder_gold+text.get('file')+\".ann\")\n",
        "      shutil.copy(path_completo+\".txt\", folder_system+text.get('file')+\".txt\")\n",
        "      quantity -= 1\n",
        "      if quantity < 1:\n",
        "        break"
      ],
      "metadata": {
        "id": "31sQxVUj_vfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder(type_text = 3, min_score = 0.0, quantity = 1, model_index = 2)"
      ],
      "metadata": {
        "id": "rk1wNaMojqmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Las tablas finales con el de test y desarrollo con train\n",
        "builder(type_text = 2, min_score = 0.0, quantity = 7, model_index = 1)"
      ],
      "metadata": {
        "id": "ONgas9UL4A_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "a76594df-2f59-46a7-e32c-0dbd06be47fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "builder(type_text = 1, min_score = 0.0, quantity = 1, model_index = 2)"
      ],
      "metadata": {
        "id": "ByIg6BUR6etL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder(type_text = 0, min_score = 0.0, quantity = 1, model_index = 2)"
      ],
      "metadata": {
        "id": "t6rjULHG6hZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "fantasy_zip = zipfile.ZipFile('/content/systemd.zip', 'w')\n",
        "for folder, subfolders, files in os.walk('/content/system'): \n",
        "    for file in files:\n",
        "        if file.endswith('.ann') or file.endswith('.txt'):\n",
        "            fantasy_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), '/content/system'), compress_type = zipfile.ZIP_DEFLATED)\n",
        "fantasy_zip.close()"
      ],
      "metadata": {
        "id": "nf4cmHj45e6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcyyW-2Thhu6"
      },
      "outputs": [],
      "source": [
        "def remove_file():\n",
        "  from pathlib import Path\n",
        "  folder_system = \"/content/system/\"\n",
        "  folder = Path(folder_system)\n",
        "  for file in folder.iterdir():\n",
        "    try:\n",
        "      file_name = file.name[0:len(file.name)-4]\n",
        "      filePath=Path(folder_system+file_name+\".ann\")\n",
        "      filePath.unlink()\n",
        "    except OSError as e:\n",
        "      print(f\"Error:{ e.strerror}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NER.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJ2AYnYH+1laT8Nx820D4J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}